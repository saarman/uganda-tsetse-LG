---
title: "RF model full – LC lakes paths"
author: "Norah Saarman"
date: "2025-06-17"
output:
  github_document:
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
RStudio Configuration:  
- **R version:** R 4.4.0 (Geospatial packages)  
- **Number of cores:** 4 (up to 32 available)   
- **Account:** saarman-np  
- **Partition:** saarman-shared-np (allows multiple simultaneous jobs)  
- **Memory per job:** 100G (cluster limit: 1000G total; avoid exceeding half)    

# Setup
```{r libraries, warning=FALSE, results=FALSE, message=FALSE}
# load only required packages
library(randomForest)
library(doParallel)
library(raster)

# base directories
data_dir  <- "/uufs/chpc.utah.edu/common/home/saarman-group1/uganda-tsetse-LG/data"
input_dir <- "../input"
results_dir <- "/uufs/chpc.utah.edu/common/home/saarman-group1/uganda-tsetse-LG/results"

# read the combined CSE + coords table + pix_dist + Env variables
V.table <- read.csv(file.path(input_dir, "Gff_cse_envCostPaths.csv"),
                    header = TRUE)

# define coordinate reference system
crs_geo <- 4326     # EPSG code for WGS84

# simple mode helper
get_mode <- function(x) {
  ux <- unique(x[!is.na(x)])
  ux[ which.max(tabulate(match(x, ux))) ]
}

# setup running in parallel
cl <- makeCluster(4)
registerDoParallel(cl)
clusterExport(cl, "get_mode")
```

# Inputs  
  - `../input/Gff_cse_envCostPaths.csv`  - Combined CSE table with coordinates (long1, lat1, long2, lat2), pix_dist = geographic distance in sum of pixels, and mean, median, mode of each Env parameter  
  
# Outputs  
  - Full RF model output
  - Projection of full RF model
  
# 1. Prepare the data
```{r, prep}
# Assign input, checking for any rows with NA
sum(!complete.cases(V.table))  # should return 0
rf_data <- na.omit(V.table)    # should omit zero rows

# Confirm that CSEdistance is numeric
rf_data$CSEdistance <- as.numeric(rf_data$CSEdistance)

# Select variables: all predictors (mean, median, mode)  
predictor_vars <- c("pix_dist",                      # geo dist
  paste0("BIO", 1:7, "_mean"),                       # mean 
  paste0("BIO", 8:11, "S_mean"),                     # mean
  paste0("BIO", 12:15, "_mean"),                     # mean
  paste0("BIO", 16:19, "S_mean"),                    # mean
  "alt_mean", "slope_mean", "riv_3km_mean",          # mean
  "samp_20km_mean", "lakes_mean",                    # mean
  paste0("BIO", 1:7, "_median"),                     # median
  paste0("BIO", 8:11, "S_median"),                   # median
  paste0("BIO", 12:15, "_median"),                   # median
  paste0("BIO", 16:19, "S_median"),                  # median
  "alt_median", "slope_median", "riv_3km_median",    # median
  "samp_20km_median", "lakes_median",                # median
  paste0("BIO", 1:7, "_mode"),                       # mode
  paste0("BIO", 8:11, "S_mode"),                     # mode
  paste0("BIO", 12:15, "_mode"),                     # mode
  paste0("BIO", 16:19, "S_mode"),                    # mode
  "alt_mode", "slope_mode", "riv_3km_mode",          # mode
  "samp_20km_mode", "lakes_mode"                     # mode
)

# subset predictors that we want to use
rf_data <- rf_data[, c("CSEdistance", predictor_vars)]
```

# 2. Build full Random Forest model 
```{r rf}
# Build full RF model
set.seed(1234)  # ensures reproducibility
rf_full <- randomForest(
  CSEdistance ~ .,
  data = rf_data,
  importance = TRUE,
  ntree = 500
)

print(rf_full)

importance(rf_full)
```

# 2. Prune variables?

## Compare mean versus median versus mode:
```{r mean-v-median-v-mode}
# Extract groups of variables by suffix
mean_vars   <- grep("_mean$", names(rf_data), value = TRUE)
median_vars <- grep("_median$", names(rf_data), value = TRUE)
mode_vars   <- grep("_mode$", names(rf_data), value = TRUE)

# Always include geographic distance
common_var <- "pix_dist"

# Build and run each model
set.seed(123438972)  # ensures reproducibility
rf_mean <- randomForest(CSEdistance ~ ., data = rf_data[, c("CSEdistance", common_var, mean_vars)], ntree = 500, importance = TRUE)
rf_median <- randomForest(CSEdistance ~ ., data = rf_data[, c("CSEdistance", common_var, median_vars)], ntree = 500, importance = TRUE)
rf_mode <- randomForest(CSEdistance ~ ., data = rf_data[, c("CSEdistance", common_var, mode_vars)], ntree = 500, importance = TRUE)

# Compare performance
c(mean = rf_mean$rsq[500] * 100,
  median = rf_median$rsq[500] * 100,
  mode = rf_mode$rsq[500] * 100)
```

Including mean of env variable along least cost paths performs the best, adding median and mode does not greatly improve the model and increases risks of over fitting...

Could add in minimum, maximum, standard deviation, range, turnover (analogous to slope) etc... later!

## Prune more variables after narrowing to mean only?

```{r mean}
# Plot variable importance
par(mar = c(5, 10, 2, 2))  # bottom, left, top, right
varImpPlot(rf_mean, main = "Mean Model Importance",cex = 0.6, pch = 19)

# Rank variables by %IncMSE (from tuned model)
imp <- importance(rf_mean)[, "%IncMSE"]
imp <- sort(imp, decreasing = TRUE)

# Multiple runs with N top predictors
# Store results
prune_results <- list()
n_list <- c(5:length(imp))

for (n in n_list) {
  top_vars <- names(imp)[1:n]
  formula_n <- as.formula(paste("CSEdistance ~", paste(top_vars, collapse = " + ")))
  
  set.seed(1234783645)
  rf_n <- randomForest(
    formula = formula_n,
    data = rf_data,
    ntree = 500,
    importance = TRUE
  )
  
  prune_results[[paste0("Top", n)]] <- rf_n
}

sapply(prune_results, function(mod) {
  c(OOB_MSE = mod$mse[500], VarExpl = mod$rsq[500] * 100)
})
```
% Variance Explained increases rapidly up to around 18 variables, after which it plateaus.

OOB MSE decreases quickly early on, with minimal gains beyond the top ~18 predictors.

## Top 18 predictors

```{r top18}
# Get variable importance
var_imp <- importance(rf_mean)[, "%IncMSE"]

# Sort and get names of top 18 predictors
top18_vars <- names(sort(var_imp, decreasing = TRUE))[1:18]

rf_top18_data <- rf_data[, c("CSEdistance", top18_vars)]
```

# 3. Tune random forest with chosen variables
```{r tune}

# Subset data for the mean-only model
#rf_mean_data <- rf_data[, c("CSEdistance", common_var, mean_vars)]
rf_mean_data <- rf_data[, c("CSEdistance", top18_vars)]

# Rename predictors by removing "_mean" for later projections
names(rf_mean_data) <- gsub("_mean$", "", names(rf_mean_data))

# Build full RF model
set.seed(10981234)  # ensures reproducibility
rf_mean18 <- randomForest(
  CSEdistance ~ .,
  data = rf_mean_data,
  importance = TRUE,
  ntree = 500
)

print(rf_mean18)
importance(rf_mean18)

# Tune mtry (number of variables tried at each split)
set.seed(92834567)
rf_mean18_tuned <- tuneRF(
  x = rf_mean_data[, -1],   # exclude response variable
  y = rf_mean_data$CSEdistance,
  ntreeTry = 500,
  stepFactor = 1.5,         # factor by which mtry is increased/decreased
  improve = 0.01,           # minimum improvement to continue search
  trace = TRUE,             # print progress
  plot = TRUE,              # plot OOB error vs mtry
  doBest = TRUE,             # return the model with lowest OOB error
  importance = TRUE
)

```

## Compare full and full tuned models (top 18 mean-only predictors)
```{r compare}
print(rf_mean18)
print(rf_mean18_tuned)

data.frame(
  Model = c("Full (default mtry)", paste("Tuned (mtry = ",rf_mean18_tuned$mtry,")")),
  MSE = c(rf_mean18$mse[rf_mean18$ntree], rf_mean18_tuned$mse[rf_mean18_tuned$ntree]),
  Rsq = c(rf_mean18$rsq[rf_mean18$ntree], rf_mean18_tuned$rsq[rf_mean18_tuned$ntree])
)

par(mar = c(5, 30, 2,2))  # bottom, left, top, right
varImpPlot(rf_mean18, main = "Full Model Importance",cex = 0.6, pch = 19)
varImpPlot(rf_mean18_tuned, main = "Tuned Full Model Importance",cex = 0.6, pch = 19)
```
That’s a very small improvement from tuning:

Default (mtry = of about 7):  
-  MSE: 0.001178  
-  RSQ: 86.21%

Tuned (mtry = 6):  
-  MSE: 0.001170
-  RSQ: 86.30%

The tuned model performs slightly better, but the gain may not be meaningful... however, it does confirm that the model is stable and that the mean-only predictors carry strong signal.

Top 18 mean-based predictors retain nearly all the explanatory power of the original full model with 42 predictors.

## Top contributors:  
- pix_dist (geographic distance)  
- samp_20km_mean (sampling effort)  
- BIO3_mean (isothermality)  
- BIO6_mean (min temperature of coldest month)  
- BIO15_mean (precipitation seasonality)  
- BIO13_mean and BIO11S_mean (mean precip. of wettest month, mean temp of coldest season)

# 4. Projection of model

env <- stack(filename = file.path(data_dir, "processed", "env_stack.tif"),
            format = "GTiff",
            overwrite = TRUE))